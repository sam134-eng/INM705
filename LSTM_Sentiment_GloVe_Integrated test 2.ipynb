{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sam134-eng/INM705/blob/main/LSTM_Sentiment_GloVe_Integrated%20test%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee06210",
      "metadata": {
        "id": "6ee06210"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# --- Ensure NLTK data is downloaded ---\n",
        "# Calling nltk.download() directly without checking for existence first,\n",
        "# as the downloader itself handles whether the resource is already present.\n",
        "# Setting quiet=False to show download progress.\n",
        "print(\"Ensuring 'punkt' NLTK resource is downloaded...\")\n",
        "nltk.download('punkt', quiet=False)\n",
        "print(\"Ensuring 'stopwords' NLTK resource is downloaded...\")\n",
        "nltk.download('stopwords', quiet=False)\n",
        "# Add the download for 'punkt_tab' as suggested by the error\n",
        "print(\"Ensuring 'punkt_tab' NLTK resource is downloaded...\")\n",
        "nltk.download('punkt_tab', quiet=False)\n",
        "\n",
        "\n",
        "# --- 1. Load and Preprocess Data ---\n",
        "# Assuming 'Tweets.csv' is available in the environment.\n",
        "# In a Colab environment, you would typically upload it first.\n",
        "# For this self-contained code, we'll assume it's loaded.\n",
        "# If running locally, ensure 'Tweets.csv' is in the same directory.\n",
        "try:\n",
        "    df = pd.read_csv(\"Tweets.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'Tweets.csv' not found. Please ensure the file is uploaded or in the correct directory.\")\n",
        "    # Create a dummy DataFrame for demonstration if file is not found\n",
        "    data = {\n",
        "        'text': [\n",
        "            \"@VirginAmerica What @dhepburn said.\",\n",
        "            \"@VirginAmerica plus you've added commercials to the experience... #fail\",\n",
        "            \"@VirginAmerica I didn't today... Must mean I need to fly it again!\",\n",
        "            \"@VirginAmerica it's really aggressive to blast obnoxious \"\n",
        "            \"loud commercials into little earbuds. #anditshardtohearanyone\",\n",
        "            \"@VirginAmerica and it's a really big bad thing about it\"\n",
        "        ],\n",
        "        'airline_sentiment': ['neutral', 'negative', 'positive', 'negative', 'negative']\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"Using a dummy DataFrame for demonstration.\")\n",
        "\n",
        "\n",
        "# Keep only relevant columns: 'text' and 'airline_sentiment'\n",
        "df = df[['text', 'airline_sentiment']]\n",
        "\n",
        "# Filter to ensure only 'positive', 'neutral', 'negative' sentiments are included\n",
        "df = df[df['airline_sentiment'].isin(['positive', 'neutral', 'negative'])]\n",
        "\n",
        "# Map sentiment labels to integers for model training\n",
        "label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "df['label'] = df['airline_sentiment'].map(label_map)\n",
        "\n",
        "# Define stopwords for text cleaning\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Cleans the input text by:\n",
        "    - Removing URLs, mentions (@), hashtags (#)\n",
        "    - Removing non-alphabetic characters\n",
        "    - Converting to lowercase\n",
        "    - Tokenizing the text\n",
        "    - Removing stopwords\n",
        "    \"\"\"\n",
        "    text = re.sub(r\"http\\S+|@\\w+|#\\w+|[^a-zA-Z\\s]\", \"\", text.lower())\n",
        "    # word_tokenize relies on the 'punkt' tokenizer data\n",
        "    tokens = word_tokenize(text)\n",
        "    return \" \".join([t for t in tokens if t not in stop_words]) # Join tokens back to string for TF-IDF\n",
        "\n",
        "# Apply the cleaning function to the 'text' column\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# --- 2. Prepare Data for TF-IDF Vectorization ---\n",
        "X = df['clean_text']\n",
        "y = df['label']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "# max_features: limits the number of features (vocabulary size)\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit the vectorizer on training data and transform both training and test data\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Convert sparse TF-IDF matrices to dense NumPy arrays, then to PyTorch Tensors\n",
        "# PyTorch's nn.Linear layer typically expects dense inputs.\n",
        "X_train_tensor = torch.tensor(X_train_tfidf.toarray(), dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)\n",
        "\n",
        "# Convert labels to PyTorch LongTensors (required for nn.CrossEntropyLoss)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Create TensorDatasets and DataLoaders for batching\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "batch_size = 64 # Define batch size for training\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# --- 3. Define PyTorch Logistic Regression Model ---\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        # Define a single linear layer for logistic regression\n",
        "        # input_dim: number of features from TF-IDF (max_features)\n",
        "        # num_classes: number of sentiment categories (3: negative, neutral, positive)\n",
        "        self.linear = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass: apply the linear transformation\n",
        "        # nn.CrossEntropyLoss will apply softmax internally, so no explicit softmax here\n",
        "        return self.linear(x)\n",
        "\n",
        "# Get input dimension (number of features from TF-IDF)\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "num_classes = len(label_map) # Number of unique sentiment classes\n",
        "\n",
        "# Instantiate the model\n",
        "model = LogisticRegressionModel(input_dim, num_classes)\n",
        "\n",
        "# --- 4. Define Loss Function and Optimizer ---\n",
        "# CrossEntropyLoss is suitable for multi-class classification\n",
        "# It combines LogSoftmax and NLLLoss (Negative Log Likelihood Loss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adam optimizer is a good general-purpose optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Learning rate can be tuned\n",
        "\n",
        "# --- 5. Train the Model ---\n",
        "num_epochs = 10 # Number of training epochs\n",
        "\n",
        "print(\"\\n--- Starting PyTorch Model Training ---\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "print(\"\\n--- Training Complete ---\")\n",
        "\n",
        "# --- 6. Evaluate the Model ---\n",
        "model.eval() # Set the model to evaluation mode\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        # Get the predicted class (index of the max log-probability)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Generate classification report\n",
        "print(\"\\nTF-IDF + PyTorch Logistic Regression Performance:\")\n",
        "print(classification_report(all_labels, all_predictions, target_names=['Negative', 'Neutral', 'Positive']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63236cc6",
      "metadata": {
        "id": "63236cc6"
      },
      "outputs": [],
      "source": [
        "# prompt: generate accuracy/loss plots\n",
        "# generate classification report\n",
        "#  generate confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', xticklabels=['Negative', 'Neutral', 'Positive'], yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1bd9cb5",
      "metadata": {
        "id": "b1bd9cb5"
      },
      "outputs": [],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip\n",
        "\n",
        "embedding_dim = 100\n",
        "glove_path = \"glove.6B.100d.txt\"\n",
        "\n",
        "glove_embeddings = {}\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        word = parts[0]\n",
        "        vector = np.array(parts[1:], dtype='float32')\n",
        "        glove_embeddings[word] = vector\n",
        "\n",
        "embedding_matrix = np.zeros((len(vocab), embedding_dim))\n",
        "for word, idx in vocab.items():\n",
        "    vector = glove_embeddings.get(word)\n",
        "    if vector is not None:\n",
        "        embedding_matrix[idx] = vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cee6750",
      "metadata": {
        "id": "5cee6750"
      },
      "outputs": [],
      "source": [
        "# --- 7. Implement and Train an LSTM Model ---\n",
        "\n",
        "# This section implements a basic LSTM model for sentiment classification\n",
        "# and prepares the data differently than the TF-IDF approach.\n",
        "\n",
        "print(\"\\n--- Starting LSTM Model Implementation and Training ---\")\n",
        "\n",
        "# --- 7.1 Data Preparation for LSTM ---\n",
        "# Requires tokenization, vocabulary creation, integer encoding, and padding\n",
        "\n",
        "# Ensure NLTK data is downloaded (already done at the beginning, but good practice to check)\n",
        "# nltk.download('punkt', quiet=False) # Already called earlier\n",
        "# nltk.download('stopwords', quiet=False) # Already called earlier\n",
        "\n",
        "# Use the clean_text function defined earlier for initial cleaning\n",
        "# We need to re-tokenize the cleaned text into lists of words for sequencing\n",
        "df['clean_tokens'] = df['clean_text'].apply(word_tokenize)\n",
        "\n",
        "# Build a vocabulary\n",
        "from collections import Counter\n",
        "\n",
        "# Flatten the list of lists into a single list of words\n",
        "all_words = [word for tokens in df['clean_tokens'] for word in tokens]\n",
        "# Count word frequencies\n",
        "word_counts = Counter(all_words)\n",
        "# Create a vocabulary, including special tokens for padding (<pad>) and unknown words (<unk>)\n",
        "# Limit vocabulary size to manage complexity\n",
        "vocab_size = 10000 # Example vocabulary size\n",
        "# Get the most common words\n",
        "most_common_words = word_counts.most_common(vocab_size - 2) # Leave space for <pad> and <unk>\n",
        "vocab = {word: i + 2 for i, (word, count) in enumerate(most_common_words)}\n",
        "vocab['<pad>'] = 0\n",
        "vocab['<unk>'] = 1\n",
        "\n",
        "# Integer encode the tokens\n",
        "def encode_tokens(tokens, vocab):\n",
        "    return [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
        "\n",
        "df['encoded_text'] = df['clean_tokens'].apply(lambda tokens: encode_tokens(tokens, vocab))\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "max_seq_length = 100 # Example maximum sequence length\n",
        "\n",
        "def pad_sequence(sequence, max_length, padding_value=0):\n",
        "    if len(sequence) > max_length:\n",
        "        return sequence[:max_length] # Truncate if too long\n",
        "    else:\n",
        "        return sequence + [padding_value] * (max_length - len(sequence)) # Pad if too short\n",
        "\n",
        "df['padded_encoded_text'] = df['encoded_text'].apply(lambda seq: pad_sequence(seq, max_seq_length, vocab['<pad>']))\n",
        "\n",
        "# Prepare data for PyTorch DataLoader\n",
        "X_lstm = torch.tensor(df['padded_encoded_text'].tolist(), dtype=torch.long) # Use LongTensor for embeddings\n",
        "y_lstm = torch.tensor(df['label'].values, dtype=torch.long)\n",
        "\n",
        "# Split data for LSTM (using the same split as TF-IDF for fair comparison, but re-preparing tensors)\n",
        "X_lstm_train, X_lstm_test, y_lstm_train, y_lstm_test = train_test_split(\n",
        "    X_lstm, y_lstm, stratify=y_lstm, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create TensorDatasets and DataLoaders for LSTM\n",
        "lstm_batch_size = 64 # Can tune this\n",
        "lstm_train_dataset = TensorDataset(X_lstm_train, y_lstm_train)\n",
        "lstm_test_dataset = TensorDataset(X_lstm_test, y_lstm_test)\n",
        "\n",
        "lstm_train_loader = DataLoader(lstm_train_dataset, batch_size=lstm_batch_size, shuffle=True)\n",
        "lstm_test_loader = DataLoader(lstm_test_dataset, batch_size=lstm_batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# --- 7.2 Define PyTorch LSTM Model ---\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, num_layers=1, dropout=0.5):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab['<pad>'])\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
        "        # Use batch_first=True so input tensors are (batch_size, seq_length, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes) # Final dense layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x has shape (batch_size, seq_length) - indices\n",
        "        embedded = self.embedding(x) # Shape: (batch_size, seq_length, embedding_dim)\n",
        "        # LSTM returns output and (hidden_state, cell_state)\n",
        "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
        "        # We'll use the hidden state from the last time step of the last layer\n",
        "        # hidden shape: (num_layers * num_directions, batch_size, hidden_dim)\n",
        "        # Assuming num_directions is 1 (default), we take hidden[-1, :, :]\n",
        "        # If bidirectional, it would be hidden[-2:, :, :].mean(0) or similar.\n",
        "        # For simplicity with num_layers=1 and unidirectional:\n",
        "        hidden_last_layer = hidden[-1, :, :] # Shape: (batch_size, hidden_dim)\n",
        "        output = self.dropout(hidden_last_layer)\n",
        "        output = self.fc(output) # Shape: (batch_size, num_classes)\n",
        "        return output\n",
        "\n",
        "# --- 7.3 Instantiate and Train the LSTM Model ---\n",
        "\n",
        "# Hyperparameters for LSTM (can be tuned)\n",
        "embedding_dim = 100 # Dimension of word embeddings\n",
        "hidden_dim = 128    # Number of features in the hidden state of the LSTM\n",
        "lstm_num_layers = 1 # Number of LSTM layers\n",
        "lstm_dropout = 0.5  # Dropout rate\n",
        "lstm_learning_rate = 0.001\n",
        "lstm_num_epochs = 10 # Example number of epochs\n",
        "\n",
        "lstm_model = LSTMClassifier(vocab_size, embedding_dim, hidden_dim, num_classes, num_layers=lstm_num_layers, dropout=lstm_dropout)\n",
        "\n",
        "# Define loss function and optimizer for LSTM\n",
        "lstm_criterion = nn.CrossEntropyLoss()\n",
        "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=lstm_learning_rate)\n",
        "\n",
        "print(\"\\n--- Training LSTM Model ---\")\n",
        "lstm_model.train()\n",
        "for epoch in range(lstm_num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in lstm_train_loader:\n",
        "        lstm_optimizer.zero_grad()\n",
        "        outputs = lstm_model(inputs)\n",
        "        loss = lstm_criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        lstm_optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(lstm_train_dataset)\n",
        "    print(f\"LSTM Epoch [{epoch+1}/{lstm_num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "print(\"\\n--- LSTM Training Complete ---\")\n",
        "\n",
        "\n",
        "# --- 7.4 Evaluate the LSTM Model ---\n",
        "\n",
        "print(\"\\n--- Evaluating LSTM Model ---\")\n",
        "lstm_model.eval()\n",
        "lstm_all_predictions = []\n",
        "lstm_all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in lstm_test_loader:\n",
        "        outputs = lstm_model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        lstm_all_predictions.extend(predicted.cpu().numpy())\n",
        "        lstm_all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Generate classification report for LSTM\n",
        "print(\"\\nLSTM Performance:\")\n",
        "print(classification_report(lstm_all_labels, lstm_all_predictions, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Generate confusion matrix for LSTM\n",
        "lstm_conf_matrix = confusion_matrix(lstm_all_labels, lstm_all_predictions)\n",
        "print(\"\\nLSTM Confusion Matrix:\")\n",
        "print(lstm_conf_matrix)\n",
        "\n",
        "# Plot confusion matrix for LSTM\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(lstm_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Neutral', 'Positive'], yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('LSTM Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- 8. Final Comparison Summary ---\n",
        "# Now you have the results for both Logistic Regression (from the previous section's final evaluation)\n",
        "# and LSTM. You can manually compare the classification reports and confusion matrices.\n",
        "\n",
        "print(\"\\n--- Final Performance Comparison Summary ---\")\n",
        "print(\"Metric       | Logistic Regression (Tuned) | LSTM\")\n",
        "print(\"-----------------|-----------------------------|------\")\n",
        "# Placeholder values - replace with the actual metrics from the reports above\n",
        "lr_report = classification_report(final_labels, final_predictions, output_dict=True)\n",
        "lstm_report = classification_report(lstm_all_labels, lstm_all_predictions, output_dict=True)\n",
        "\n",
        "print(f\"Accuracy     | {lr_report['accuracy']:.4f}               | {lstm_report['accuracy']:.4f}\")\n",
        "print(f\"Precision (Neg)| {lr_report['0']['precision']:.4f}          | {lstm_report['0']['precision']:.4f}\")\n",
        "print(f\"Recall (Neg) | {lr_report['0']['recall']:.4f}             | {lstm_report['0']['recall']:.4f}\")\n",
        "print(f\"F1-Score (Neg)| {lr_report['0']['f1-score']:.4f}                 | {lstm_report['0']['f1-score']:.4f}\")\n",
        "print(f\"Precision (Neu)| {lr_report['1']['precision']:.4f}          | {lstm_report['1']['precision']:.4f}\")\n",
        "print(f\"Recall (Neu) | {lr_report['1']['recall']:.4f}             | {lstm_report['1']['recall']:.4f}\")\n",
        "print(f\"F1-Score (Neu)| {lr_report['1']['f1-score']:.4f}                 | {lstm_report['1']['f1-score']:.4f}\")\n",
        "print(f\"Precision (Pos)| {lr_report['2']['precision']:.4f}          | {lstm_report['2']['precision']:.4f}\")\n",
        "print(f\"Recall (Pos) | {lr_report['2']['recall']:.4f}             | {lstm_report['2']['recall']:.4f}\")\n",
        "print(f\"F1-Score (Pos)| {lr_report['2']['f1-score']:.4f}                 | {lstm_report['2']['f1-score']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee8b0bf",
      "metadata": {
        "id": "1ee8b0bf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# The variables `final_labels` and `final_predictions` were used in the summary\n",
        "# but were not defined in the TF-IDF Logistic Regression evaluation section.\n",
        "# They should be replaced with `all_labels` and `all_predictions` respectively.\n",
        "\n",
        "# --- 8. Final Comparison Summary ---\n",
        "# Now you have the results for both Logistic Regression (from the previous section's final evaluation)\n",
        "# and LSTM. You can manually compare the classification reports and confusion matrices.\n",
        "\n",
        "print(\"\\n--- Final Performance Comparison Summary ---\")\n",
        "print(\"Metric         | Logistic Regression | LSTM\")\n",
        "print(\"-----------------|---------------------|------\")\n",
        "# Use the actual variables from the TF-IDF evaluation\n",
        "lr_report = classification_report(all_labels, all_predictions, output_dict=True)\n",
        "lstm_report = classification_report(lstm_all_labels, lstm_all_predictions, output_dict=True)\n",
        "\n",
        "print(f\"Accuracy       | {lr_report['accuracy']:.4f}         | {lstm_report['accuracy']:.4f}\")\n",
        "# Access individual class metrics safely, handling potential missing keys (though unlikely here)\n",
        "neg_lr = lr_report.get('0', {})\n",
        "neu_lr = lr_report.get('1', {})\n",
        "pos_lr = lr_report.get('2', {})\n",
        "\n",
        "neg_lstm = lstm_report.get('0', {})\n",
        "neu_lstm = lstm_report.get('1', {})\n",
        "pos_lstm = lstm_report.get('2', {})\n",
        "\n",
        "\n",
        "print(f\"Precision (Neg)| {neg_lr.get('precision', 0.0):.4f}         | {neg_lstm.get('precision', 0.0):.4f}\")\n",
        "print(f\"Recall (Neg)   | {neg_lr.get('recall', 0.0):.4f}         | {neg_lstm.get('recall', 0.0):.4f}\")\n",
        "print(f\"F1-Score (Neg) | {neg_lr.get('f1-score', 0.0):.4f}         | {neg_lstm.get('f1-score', 0.0):.4f}\")\n",
        "\n",
        "print(f\"Precision (Neu)| {neu_lr.get('precision', 0.0):.4f}         | {neu_lstm.get('precision', 0.0):.4f}\")\n",
        "print(f\"Recall (Neu)   | {neu_lr.get('recall', 0.0):.4f}         | {neu_lstm.get('recall', 0.0):.4f}\")\n",
        "print(f\"F1-Score (Neu) | {neu_lr.get('f1-score', 0.0):.4f}         | {neu_lstm.get('f1-score', 0.0):.4f}\")\n",
        "\n",
        "print(f\"Precision (Pos)| {pos_lr.get('precision', 0.0):.4f}         | {pos_lstm.get('precision', 0.0):.4f}\")\n",
        "print(f\"Recall (Pos)   | {pos_lr.get('recall', 0.0):.4f}         | {pos_lstm.get('recall', 0.0):.4f}\")\n",
        "print(f\"F1-Score (Pos) | {pos_lr.get('f1-score', 0.0):.4f}         | {pos_lstm.get('f1-score', 0.0):.4f}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}